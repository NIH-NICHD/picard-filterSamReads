app_content:
    code_package: 63bb2824212b0d420594b51c
    entrypoint: main.nf
class: nextflow
cwlVersion: None
doc: "# picard-filterSamReads\n\nUsing the work that Matthew Galbraith outlined -\
    \ make a nextflow workflow that allows this to be run and scaled.\n\n\n## use\
    \ conda to keep a clean environment\n\ncreate an environment to ensure all pieces\
    \ required are installed in a clean environment.\nHere we call it `picard`.\n\n\
    Conda environment management is rich and nearly complete.  Current some problems\
    \ - for example samtools install via conda does not work.\n\nSearch and use [anaconda](https://anaconda.org/)\
    \ for packages. \n\n```bash\nconda create -n picard -y\n```\n\n## install [nextflow](https://nextflow.io)\n\
    \nWe develop and install our workflow using nextflow -- we need to install it\
    \ :)\n\n```bash\nconda install -c bioconda nextflow\n```\n\n## manage your GitHub\n\
    \nKeep track of everything on GitHub - final workflow will be `main.nf` with configuration\
    \ in `nextflow.config`.\n\nNeed to use the command line interface routine `gh`.\n\
    \n```bash\nconda install -c conda-forge gh\n```\n\nNeed to use your [GitHub token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)\
    \ to authenticate.\n\n```bash\ngh auth login\n```\n\n## adding emacs editor\n\n\
    Sorry the editor is great in [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/),\
    \ I like emacs\n\n```bash\nconda install -c conda-forge emacs -y\n```\n\n## Manual\
    \ check of steps\n\nTwo routines used -- `picard FilterSamReads` and `samtools\
    \ fastq`\n\n\n### Samtools from the command line\n\n```bash\nsamtools fastq --reference\
    \ data/Homo_sapiens_assembly38.fasta -1 HTP0003A.1.fastq -2 HTP0003A.2.fastq HTP0003A_filtered.cram\n\
    [M::bam2fq_mainloop] discarded 0 singletons\n[M::bam2fq_mainloop] processed 1613932\
    \ reads\n```\n\nChecking results (4 lines per read in a fastq file)\n\n```bash\n\
    (picard) wc -l *.fastq\n  3227864 HTP0003A.1.fastq\n  3227864 HTP0003A.2.fastq\n\
    \  6455728 total\n```\n\nDouble check the numbers -\n\n3227864 / 4 = 806966\n\n\
    806966 * 2 = 1613932 Reads\n\nIt adds up.\n\n### Samtools from containerized image\n\
    \n```bash\ndocker run -it -v $PWD:$PWD -w $PWD samtools samtools fastq --reference\
    \ data/Homo_sapiens_assembly38.fasta -1 HTP0003A.1.fastq -2 HTP0003A.2.fastq 2022Apr23ManualRun/HTP0003A_filtered.cram\n\
    .fastq -2 HTP0003A.2.fastq 2022Apr23ManualRun/HTP0003A_filtered.cram \n[M::bam2fq_mainloop]\
    \ discarded 0 singletons\n[M::bam2fq_mainloop] processed 1613932 reads\n```\n\n\
    response is identical.\n\n### Recap\n\nWe made two containers, now we have stitched\
    \ those together as two processes.   Making sure the file names are updated based\
    \ upon the input file name and then into a workflow.\n\n## making main.nf\n\n\
    Using the nextflow documentation faq for [How do I process multiple input files\
    \ in parallel?](https://www.nextflow.io/docs/latest/faq.html#how-do-i-process-multiple-input-files-in-parallel)\n\
    \n'*updated Jan 8 2022*'\n\nUsing the steps outlined by our colleague '*Nick*'\n\
    \n<ins>Pseudo code</ins>\n1. a. samtools view to convert cram to sam with header\
    \ file. \n\n   b. samtools view to start the new output file with header only.\
    \ \n   \n   c. samtools view to filter based upon a provided filter string (see\
    \ script below - narrow to chromosome, gene of interest). \n   \n2. picard SamToFastq\
    \ to extract the paired reads overlapping the newly extracted region and produced\
    \ the R1_fastq and R2_fastq files. \n3. fastqc - performs quality control analysis\
    \ on the fastq files extracted using a container built from [fastqc-docker](https://github.com/adeslatt/fastqc-docker).\
    \ \n4. multiqc - creates a final quality control report using the output from\
    \ fastqc using a container built from [multiqc-docker](https://github.com/adeslatt/multiqc-docker).\
    \ \n\n## executing\n\nthe input requirements can be obtained from running with\
    \ option `--help`\n\n```bash\n(picard) nichdm02209715:picard-filterSamReads deslattesmaysa2$\
    \ nextflow run main.nf --help\nN E X T F L O W  ~  version 21.10.6\nLaunching\
    \ `main.nf` [modest_austin] - revision: 9d1ff459fd\n\nUsage:\nThe typical command\
    \ for running the pipeline is as follows:\n\nInputs Options:\n--input        \
    \       Input cram\n--max_records_in_ram  For picard tools to specify the maximum\
    \ records in ram (default is 500000).\n--filter_string       String to use to\
    \ filter region from cram (e.g. \"grep -e chr6 -e HLA -e \"*\"\")\n--outdir  \
    \            The directory for the filtered cram (default is CRAMS_filtered).\n\
    --outputfile          test place holder - shouldn't be necessary\n--reference_fasta\
    \     The assembly reference (Homo sapiens assembly as a fasta file.\n--tracedir\
    \            Where the traces and DAG and reports are kept.\n```\n\n\nTo execute\
    \ the test file, the following command was run:  \n\nNote for the test, we used\
    \ the filter string `*\"grep -e chr22 -e USP18 -e \\\"*\\\"\"*'\n\n```bash\nnextflow\
    \ run main.nf \\\n--input data/test.chr22.Aligned.sortedByCoord.out.cram \\\n\
    --filter_string \"grep -e chr22 -e USP18 -e \\\"*\\\"\" \\\n--outdir \"test_output\"\
    \ \\\n--outputfile \"test_outputfile\" \\\n--reference_fasta \"data/GRCh38.primary_assembly.genome.chr22.fa\"\
    \ \\\n--tracedir \"execution_trace\" \\\n-with-trace \\\n-with-report \\\n-with-dag\
    \ \"execution_trace/test_output.png\" \\\n-with-timeline\n```\n\nCommand when\
    \ executed on my macbook pro ran very quickly with the limited data files and\
    \ isolated to chr22 segment of the human genome.   GitHub actions can be set up\
    \ to ensure that this nextflow script runs at all times regardless of changes.\n\
    \n## Execution Trace\n\n[Nextflow](https://www.nextflow.io) has nice features\
    \ for creating execution report with timeline and resource details.  \n\nThese\
    \ may be found in the [execution trace directory](https://github.com/adeslatt/picard-filterSamReads/blob/main/execution_trace/)\n\
    \n| Nextflow Execution Artefacts   |  Test Output    |\n| ------------- | ---------------------------------------------------------------------------\
    \ |\n| [The Nextflow execution report](https://www.nextflow.io/docs/latest/tracing.html#execution-report)|\
    \ <img src=\"https://github.com/adeslatt/picard-filterSamReads/blob/main/assets/NextflowWorkflowReport.png\"\
    \ width=\"600\" align=\"right\"> |\n| [The Nextflow Tasks Details](https://www.nextflow.io/docs/latest/tracing.html#tasks)\
    \ | <img src=\"https://github.com/adeslatt/picard-filterSamReads/blob/main/assets/NextflowWorkflowTasksDetail.png\"\
    \ width=\"600\" align=\"right\"> |\n| [The Nextflow Resource Usage](https://www.nextflow.io/docs/latest/tracing.html#resource-usage)\
    \ | <img src=\"https://github.com/adeslatt/picard-filterSamReads/blob/main/assets/NextflowReportResourceUsage.png\"\
    \ width=\"600\" align=\"right\"> |\n\nTo view the details, you can download the\
    \ html files to your own computer and view within your browser (Chrome preferred)\n\
    \n## Multiqc and Fastqc results\n\nPhil Ewels continues to produce so many wonderful\
    \ tools, including [Multiqc](https://multiqc.info)\n\nThe output of the running\
    \ of fastqc and multiqc on the test files may be found in the [test output directory](https://github.com/adeslatt/picard-filterSamReads/blob/main/test_output/)\n\
    \n| Multiqc & Fastqc Execution Artefacts   |  Test Output    |\n| -------------\
    \ | ---------------------------------------------------------------------------\
    \ |\n| [The Multiqc](https://multiqc.info/)| <img src=\"https://github.com/adeslatt/picard-filterSamReads/blob/main/assets/MultiQCPicture.png\"\
    \ width=\"600\" align=\"right\"> |\n| [The Fastqc details](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/)|\
    \ <img src=\"https://github.com/adeslatt/picard-filterSamReads/blob/main/assets/FastQCPicture.png\"\
    \ width=\"600\" align=\"right\">|\n\nTo view the complete details, download the\
    \ html files to your own computer and view within your browser (Chrome preferred)\n\
    \n## Uploading Nextflow Workflow onto Cavatica\n\nA nice feature of the Cavatica\
    \ platform - now we can upload our Nextflow workflow onto Cavatica.   \n\nThe\
    \ steps are as follows:\n\n1. Create your workflow and put it into GitHub\n\n\
    2. Create a credentials file placed here `~/.sevenbridges/credentials`.  The content\
    \ looks like this:\n\n```bash\n[deslattesmaysa2]\napi_endpoint = https://cavatica-api.sbgenomics.com/v2\n\
    auth_token = [your developers token]\n```\n\nThe name in between the `[]` is your\
    \ username on the platform.\n\n3. git clone your GitHub workflow in a clean directory.\
    \  This is important because the process of uploading as an application onto Cavatica\
    \ zips up the directory - and you do not want your old work directories to be\
    \ zipped inside!\n\n4. Install the sbpack_nf routine.  This is done with pip\n\
    \n```bash\npip3 install sbpack\n```\n\n5. Now use the [sbpack_nf](https://docs.cavatica.org/reference/bring-nextflow-apps-to-cavatica#sbpack_nf-command-reference)\
    \ command.  See the link gives all the details for the options.\n\n```bash\nsbpack_nf\
    \ --profile deslattesmaysa2 --appid matthew.galbraith/kf-htp-cram-hla-extractions/picard-filterSamReads-nf\
    \ --sb-doc /Users/deslattesmaysa2/projects/picard-filterSamReads/README.md --entrypoint\
    \ main.nf --workflow-path /Users/deslattesmaysa2/projects/picard-filterSamReads\n\
    ```\n\n6. Edit the `sb_nextflow_schema.yaml` to accept the input files using the\
    \ details as outlined in the [Cavatica Nextflow help pages](https://docs.cavatica.org/v1.0/docs/bring-nextflow-apps-to-cavatica#section-optimizing-the-converted-app-for-execution-in-seven-bridges-environments)\n\
    \nThe final form of the `sb_nextflow_schema.yaml` may be found in this repository\
    \ [sb_nextflow_schema.yaml](https://github.com/adeslatt/picard-filterSamReads/blob/main/sb_nextflow_schema.yaml)\n\
    \n7. upload the edited `sb_nextflow_schema.yaml`\n\nNote that this is done with\
    \ the `sbpack` command.\n\n```bash\nsbpack deslattesmaysa2 matthew.galbraith/picard-test/picard-filtercramfile-nf\
    \  sb_nextflow_schema.yaml\n```\n\nAnd then it is an application ready to be used\
    \ on the cavatica platform.\n\n## Workflow Overview DAG\n\nGenerated when running\
    \ Nextflow - here is the process graph\n\n<p>\n<img src=\"https://github.com/adeslatt/picard-filterSamReads/blob/main/execution_trace/test_output.png\"\
    \ width=\"1000\">\n</p>\n\n\n\n\n\n\n"
inputs:
-   id: reference_sequence
    inputBinding:
        prefix: --reference_sequence
    type:
    - File
    - 'null'
-   id: run_name
    inputBinding:
        prefix: --run_name
    type:
    - string
    - 'null'
-   id: max_records_in_ram
    inputBinding:
        prefix: --max_records_in_ram
    type:
    - string
    - 'null'
-   id: filter_string
    inputBinding:
        prefix: --filter_string
    type:
    - string
    - 'null'
-   doc: You will need to create a design file with information about the samples
        in your experiment before running the pipeline. Use this parameter to specify
        its location. It has to be a comma-separated file with 3 columns, and a header
        row. See [usage docs](https://nf-co.re//usage#samplesheet-input).
    id: input
    inputBinding:
        prefix: --input
    label: Path to comma-separated file containing information about the samples in
        the experiment.
    type:
    - File
-   id: outdir
    inputBinding:
        prefix: --outdir
    label: Path to the output directory where the results will be saved.
    sbg:toolDefaultValue: ./results
    type:
    - Directory
    - 'null'
-   id: help
    inputBinding:
        prefix: --help
    label: Display help text.
    type:
    - boolean
    - 'null'
-   id: tracedir
    inputBinding:
        prefix: --tracedir
    label: Directory to keep pipeline Nextflow logs and reports.
    sbg:toolDefaultValue: ${params.outdir}/pipeline_info
    type:
    - File
    - 'null'
outputs:
-   doc: This is a template output. Please change glob to directories specified in
        publishDir in the workflow.
    id: output_directory
    outputBinding:
        glob: $(inputs.outdir)
    type: Directory
requirements:
-   class: InlineJavascriptRequirement
-   class: InitialWorkDirRequirement
    listing:
    - $(inputs.input)
    - $(inputs.reference)
    - $(inputs.outdir)
    - $(inputs.tracedir)
